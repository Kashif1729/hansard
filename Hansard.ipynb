{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hansard Analysis\n",
    "\n",
    "This notebook contains code to analyse Hansard, the official record of every spoken or written contribution made in the Houses of Parliament from 1803 to the present day."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why bother?\n",
    "\n",
    "Looking at changes in political discourse over time is fascinating. We can infer a lot about which issues were prioritised by different governments, how Members of Parliament responded to global events, when emerging technologies were first mentioned in Parliament, and how the tone surrounding different issues has changed.\n",
    "\n",
    "![Hansard](https://assets3.parliament.uk/iv/main-large//ImageVault/Images/id_10860/scope_0/ImageVaultHandler.aspx.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading the archives\n",
    "\n",
    "The online Hansard archive (available at https://hansard.parliament.uk/) is an incredibly rich source of information, and is free to access. It's also a bit of a mess; this means it's more efficient to download a local copy of Hansard and search that, so we'll start off by writing some code to automatically download one HTML file for every day's worth of Parliamentary debate.\n",
    "\n",
    "Downloading all this will take a good couple of days even with the code running continuously, but on the plus side your non-technical friends will think you're orders of magnitude more intelligent than you actually are if you intersperse every conversation with \"sorry, I just need to go and check my code is still running.\" For bonus points, switch the colour scheme on your terminal to green on black and be sure to accidentally on purpose give them a glimpse of the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries \n",
    "\n",
    "import urllib2 # requests and grabs information from web pages\n",
    "from bs4 import BeautifulSoup # parses and searches HTML files\n",
    "import matplotlib.pyplot as plt # plots results\n",
    "import re # uses regular expressions to efficiently search large bodies of text\n",
    "import os \n",
    "import math\n",
    "import time\n",
    "from glob import glob \n",
    "import calendar\n",
    "from datetime import datetime "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading 1803-2004 \n",
    "\n",
    "The online archives for 1803-2005, 2005-2010, and 2010-2017 are all held in slightly different places and in slightly different formats because of reasons, so we have three different functions to download each of these.\n",
    "\n",
    "We cycle through every possible date in our time range and check whether a page corresponding to that date exists in the Hansard archive. If a page exists, that means there was a Parliamentary sitting that day and we can download the associated records. If a page doesn't exist, we can assume Parliament wasn't sitting. This is the programmatic equivalent of accessing the Hansard archive in any web browser, navigating to a particular date, and manually downloading all debates listed under the House of Commons. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to save daily Hansard records from 1803-2004 locally as HTML files\n",
    "def saveOldContribs():\n",
    "\n",
    "    for year in range(1803,2005):\n",
    "        for month in range(1,13):\n",
    "            for day in range(1,32):\n",
    "\n",
    "                monthName = calendar.month_name[month].lower()[0:3]\n",
    "                contentsURL = \"http://hansard.millbanksystems.com/sittings/\"+str(year)+\"/\"+monthName+\"/\"+str(day).zfill(2)\n",
    "\n",
    "                try: \n",
    "                    print \"trying date: \", str(year)+' '+str(month)+' '+str(day).zfill(2)\n",
    "                    contentsPage = urllib2.urlopen(contentsURL).read()\n",
    "                    contentsSoup = BeautifulSoup(contentsPage,'lxml')\n",
    "                    print \"success!\"\n",
    "                    saveFile = open('./XXXX'+ ' '+str(year)+' '+str(month)+' '+str(day).zfill(2)+'.html', 'w')\n",
    "                    commonsSection = contentsSoup.find_all(\"ol\", {\"class\": \"xoxo first\"})[0]\n",
    "                    for link in commonsSection.find_all('a', href=True):\n",
    "                        linkURL = \"http://hansard.millbanksystems.com\"+link['href']\n",
    "                        print linkURL\n",
    "                        linkPage = urllib2.urlopen(linkURL).read()\n",
    "                        saveFile.write(linkPage)\n",
    "\n",
    "                    saveFile.close()\n",
    "                except:\n",
    "                    print \"page not found!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading 2005-2010\n",
    "\n",
    "Note especially the skillful use of 'sesh' as a variable name. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to save daily Hansard records from 2005-2010 locally as HTML files\n",
    "def saveMidContribs(): \n",
    "\n",
    "    validSessions = ['200405 2004 11','200405 2004 12','200405 2005 01','200405 2005 02','200405 2005 03','200405 2005 04',\n",
    "                     '200506 2005 05','200506 2005 06','200506 2005 07','200506 2005 08','200506 2005 09','200506 2005 10',\n",
    "                     '200506 2005 11','200506 2005 12','200506 2006 01','200506 2006 02','200506 2006 03','200506 2006 04',\n",
    "                     '200506 2006 05','200506 2006 06','200506 2006 07','200506 2006 08','200506 2006 09','200506 2006 10',\n",
    "                     '200506 2006 11','200607 2006 12','200607 2007 01','200607 2007 02','200607 2007 03','200607 2007 04',\n",
    "                     '200607 2007 05','200607 2007 06','200607 2007 07','200607 2007 08','200607 2007 09','200607 2007 10',\n",
    "                     '200708 2007 11','200708 2007 12','200708 2008 01','200708 2008 02','200708 2008 03','200708 2008 04',\n",
    "                     '200708 2008 05','200708 2008 06','200708 2008 07','200708 2008 08','200708 2008 09','200708 2008 10',\n",
    "                     '200708 2008 11','200809 2008 12','200809 2009 01','200809 2009 02','200809 2009 03','200809 2009 04',\n",
    "                     '200809 2009 05','200809 2009 06','200809 2009 07','200809 2009 08','200809 2009 09','200809 2009 10',\n",
    "                     '200809 2009 11','200910 2009 12','200910 2010 01','200910 2010 02','200910 2010 03','200910 2010 04',\n",
    "                     '201011 2010 05','201011 2010 06','201011 2010 07','201011 2010 08','201011 2010 09','201011 2010 10',\n",
    "                     '201011 2010 11','201011 2010 12']\n",
    "\n",
    "    for sesh in validSessions:\n",
    "        for x in range(1,32):\n",
    "            \n",
    "            day = '%02d'%(x)\n",
    "            session, year, month = sesh.split(\" \")\n",
    "\n",
    "            date = year[2:4]+month+day\n",
    "\n",
    "            print \"trying date \",date\n",
    "\n",
    "            try:\n",
    "                currentDate = time.strptime(day+'/'+month+'/'+year,'%d/%m/%Y')\n",
    "\n",
    "                if year[2] == '0':\n",
    "                    dateShort = year[3:4]+month+day\n",
    "                else:\n",
    "                    dateShort = date\n",
    "\n",
    "                if time.strptime('04/05/2006','%d/%m/%Y') < time.strptime(day+'/'+month+'/'+year,'%d/%m/%Y'):\n",
    "                    pageFlag = \"-0001.htm\"\n",
    "                else:\n",
    "                    pageFlag = \"-01.htm\"\n",
    "\n",
    "                if  time.strptime('08/11/2006','%d/%m/%Y') < time.strptime(day+'/'+month+'/'+year,'%d/%m/%Y'):\n",
    "                    volFlag = \"cm\"\n",
    "                else:\n",
    "                    volFlag = \"vo\"\n",
    "\n",
    "                contentsURL = \"https://publications.parliament.uk/pa/cm\"+session+\"/cmhansrd/\"+volFlag+date+\"/debtext/\"+dateShort+pageFlag\n",
    "                contentsPage = urllib2.urlopen(contentsURL).read()\n",
    "                contentsSoup = BeautifulSoup(contentsPage,'lxml')\n",
    "\n",
    "                if contentsSoup.find(\"h1\") is None:\n",
    "                    print \"success!\"\n",
    "                    print \"...\"\n",
    "                    saveFile = open('./'+session+' '+year+' '+month+' '+day+'.html', 'w')\n",
    "                    for pageNum in range(1,2000):\n",
    "                        print \"trying page \",pageNum\n",
    "                        if time.strptime('04/05/2006','%d/%m/%Y') < time.strptime(day+'/'+month+'/'+year,'%d/%m/%Y'):\n",
    "                            pageFlag = '-'+str(pageNum).zfill(4)+'.htm'\n",
    "                        else:\n",
    "                            pageFlag = '-'+str(pageNum).zfill(2)+'.htm'\n",
    "\n",
    "                        searchURL = \"https://publications.parliament.uk/pa/cm\"+session+\"/cmhansrd/\"+volFlag+date+\"/debtext/\"+dateShort+pageFlag\n",
    "                        searchPage = urllib2.urlopen(searchURL).read()\n",
    "                        searchSoup = BeautifulSoup(searchPage,'lxml')\n",
    "                        if searchSoup.find(\"h1\") is None:\n",
    "                            saveFile.write(searchPage)\n",
    "                        else:\n",
    "                            break\n",
    "                    saveFile.close()\n",
    "                else:\n",
    "                    print \"no debates on this day!\"\n",
    "\n",
    "            except:\n",
    "                print \"not a valid date!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading 2011-2017"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
